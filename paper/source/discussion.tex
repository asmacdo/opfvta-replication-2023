\section{Discussion}

\subsection{Strengths of the original article as a reexecution target}
% this should be the shortest
The original paper made a significant effort to encapsulate all
components of the analysis as code, including the generation of images
and the rendering of the final pdf. Once properly installed, the
replication required little knowledge of the implementation details.

\subsection{Challenges}
Installation was challenging primarily because the process of installing
software on Gentoo is very slow. Building the container image took
about five hours, which lead to a slow development cycle where mistakes
were expensive.


%TODO avoiding duplication of paths
%TODO never hardcode abs paths (not that we did herE)
%TODO also avoid hard-coding relative paths which rely on specific execution directory
%TODOadd on set -eu -c pipefail

%TODO Latency for re-execution, checking intermediary steps

\subsection{Lessons Learned}
% mention decimal rounding for localized text diff-ing

\begin{itemize}
\item Bash: scripts should fail upon first error -- ``set -eu`` or otherwise (approach taken here) ``|| exit 1``.
  We switched because e.g. with ``|| exit 1`` you would not exit upon undefined variable etc.
  \item Optimize the development cycle time.
    \begin{lstlisting}
    (bugfix -> rebuild container image -> push -> pull from compute -> run)
    \end{lstlisting}
    If this takes a long time, very little work will get done.

    \begin{itemize}
      \item Automate the build, push.
      \item Keep container images small:
        \begin{itemize}
          \item Keep data out of the images.
          \item Use a small base image like alpine for your own containers.
        \end{itemize}
      \item Establish your reproducible base container environment.
        In case of Gentoo: Pin the Gentoo repo as soon as dependencies are working; this will allow some use of the cache.
        In case of Debian-based: use NeuroDebian tool nd\_freeze and call it early in the recipe~\supercite{TODO}.
        NeuroDocker~\supercite{TODO} could be used to streamline creation of 
      \item Copy as little into the image as possible - bind mount what is needed
        \begin{itemize}
        \item Each unnecessary thing copied in may force a rebuild if it changes.
        \item Bind-mount any software/scripts/data which might remain a subject to change
        \end{itemize}
    \end{itemize}

  \item Modularize the workflow into isolated components to make the reuse most efficient.

    The efficiency estimation might differ between developers and users.
    The tricks with ``bind mounting'' might provide some remedy for the developers while reusing the same container compartmentalization as destined for a user.
    \begin{itemize}
    \item
      Separate containers for major steps of data analysis, e.g., pre-processing and evaluation containers.
      In this study we had a single container for both steps and it added additional burden since to fix one of the stages we were affecting container for the both of them. 
    \item
      Standardize container ``interfaces'' to an existing standard like Boutiques or BIDS-App.
      BIDS-App interfaces also facilitate enabling ``per-participant'' processing, which then allows for mass-parallelization on HPC across subjects.
    \item
      Use a series of container ``steps'' rather than a ``monolithic container'' (analogy to microservices).
      In the enterprise world, the push to modernize has often started with "shoving what we have into containers," and this approach frequently is a headache and does not have the "cloud-native" benefits. Is it even worth doing this step?
      Instead, what is recommended for enterprise apps is to break the monolith into microservices that can all be deployed, scaled, and upgraded independently.
      In science, it is obviously not as important to scale and upgrade without downtime, but the concept may still hold.
      The way opfvta is organized makes it challenging to modularize because it was designed for reproducibility and that was accomplished by abstracting the internal workings from a single top-level "black box" interface.
      In this paper, we have created the monolith, which suffers from slow builds, large sizes, and, therefore, a slow development cycle.
      \item What does a "chain" of BIDS apps look like?  Answer: mriqc, fmriprep, fitlins... The glue between -- data standards, but the software on how to invoke -- WiP, no unified way. WiP on formalizing BIDS-App interfaces more (https://bids.neuroimaging.io/bep027) which ATM assumes use of Boutique descriptors.
      \item Easier and faster to debug and iterate.
      \item Ideally, use images created by the projects with no modifications, i.e., for fmriprep use fmriprep container.
      \item Each container should have a well-defined "input" and "output" so it can be easily spotted which steps have failed.
    \end{itemize}
  
  \item Separate jobs by participant where possible.
    \begin{itemize}
      \item Instead of deploying 1 job to analyze all participants, deploy many jobs to each analyze 1 participant.
      \item Use scheduler like SLURM to manage resources rather than internal code.
    \end{itemize}
  
  \item Automate the orchestration of data.
  
  \item With singularity, automate the build from OCI push to datald repo, and then pull + datalad get from compute resource.
\end{itemize}


\subsection{Outlook}

- The linking of the data might make re-use/hacking of the article for variant purposes more feasible
- Automation of reference results
- Separation of components for re-use
