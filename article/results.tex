\section{Results}
% What we accomplihesd, everything which we created, invented, etc. should preferentially go here.
% Descriptive, opinions either absent, or as objective-ish comments when facts are stated.
% Should, could, might, etc. sparingly and ideally not here but in discussion.

\subsection{Repository Structure}
In order to improve the reexecution reliability of the OPVFTA article we have constructed a parent repository which leverages Git to link all reexecution requirements.
This framework leverages Git submodules for resource referencing, and DataLad \cite{datalad} in order to permit Git integration with data resources.

These resources include the original article, the raw data it operates on, and a reference mouse brain templates package, as submodules.
Additionally, it directly tracks the code required to coordinate the OPFVTA article reexecution and subsequent generation of \emph{this} article.
The code unique to the reexecution framework consists of container image generation and container execution instructions, and a Make system for process coordination (\cref{fig:topology}).

The Make system is structured into a top-level Makefile, which can be used for container image regeneration and upload, article reexecution in a containerized environment, and meta-article production.
Two article regeneration Make targets exist, for both the Open Container Initiative standard, and Singularity.
Both article reexecution targets wrap the \texttt{produce\_analysis.sh} script, which is a thing compatibility layer accessing the Make system of the original article.
The meta-article targets redirect to a Makefile in the \texttt{article/} child directory, which contains this document's human-readable text in \TeX format, alongside scripts for generating dynamical elements based on the reexecution results seen in the \texttt{outputs/} directory.

%TODO yoh Can we get a DOI/ISBN for the following YODA reference? https://handbook.datalad.org/en/latest/basics/101-127-yoda.html
The layout constructed for this study thus provides robust provenance tracking and constitutes an instantiation of the YODA principle (a recursive acronym for “YODAs Organigram on Data Analysis”).

This repository structure diverges from the original reference article in directly linking the data at the repository level, as opposed to relying on its installation via a package manager.
%TODO chr Maybe add caveats to this in discussion
This leverages Git to provide basic dependency resolution, which adds portability across operating system choices as well as finer-grained version control.
Within the context of container usage, this also affords the advantage of keeping the data packages outside of container image generation logic, and not adding their disk space requirements to container images.

Notably, the article source code itself is not duplicated or further edited here, but handled as a Git submodule itself, with all proposed improvements being recorded in the original upstream repository.

\begin{figure}
	\centering
	\includegraphics[clip,width=0.99\textwidth]{figs/topology.pdf}
	\caption{
		\textbf{The directory topology of the reexecution framework nests all requirements and includes a Make system for process coordination.}
		Depicted is a directory tree topology of the repository coordinating OPFVTA re-execution.
		Nested directories are represented by nested boxes, and Git submodules are highlighted with orange borders.
		The article reexecution PDF results are highlighted in light green, and the PDF of the resulting meta-article (i.e. this article) is highlighted in light blue.
	}
	\label{fig:topology}
\end{figure}


%TODO: Something *descriptive* about how this new layout allows for more of a plug-in structure.

\subsection{Resource Refinement}

As a notable step in our article reproduction effort, we have updated resources previously only available as tarballs (i.e. compressed \texttt{tar} archives), to DataLad.
This refinement affords both the possibility to cherry-pick only required data files from the data archive (as opposed to requiring a full archive download), as well as more fine-grained version tracking capabilities.
In particular, our work encompassed the re-write of the Mouse Brain Templates package \cite{mbt05} Make system.
In its new release \cite{mbt10}, developed as part of this study, Mouse Brain Templates now publishes tarballs, as well as DataLad-accessible unarchived individual template files.


\subsection{Reproduction Quality}

% TODO - make proper latex etc:
%  Additional aspects which were not foreseeing in the original execution making it impossible to reexecute to the identical result - no randomization seed was provided or recorded.

As a top-level view of reexecution results we have produced a simple infrastructure to analyze reproduction quality.
This provides both quality control for successful reexecution as well as a showcase of how automatic article reexecutability can be leveraged to evaluate \textit{reproducibility} at a glance.

For this purpose we compare the difference between the Historical Manuscript Record — a product of the original executable article generation — and multiple results of the Novel Workflow.
Reproduction differences between the article versions are extracted by evaluating rasterized page-wise PDF difference (\ref{fig:diff_pages}).


\begin{figure}
	\centering
	\includegraphics[clip,width=0.99\textwidth]{figs/diff_pages.pdf}
	\caption{
		\textbf{Page-wise visual differences between the Historical Manuscript Record and the Novel Workflow Reexecution help identify overall reproduction fidelity, and identify pages with noteworthy differences.}
		Depicted are rasterized document differences, weighted 1 for changes in any pixel color channel, and rounded to four decimal points.
		Error bars represent the \nth{95} percentile confidence interval.
	}
	\label{fig:diff_pages}
\end{figure}


This overview shows a consistent minimum baseline of differences, around $10^{-4}$ (i.e. \SI{0.01}{\percent}), best seen in pages 6 to 10.
When examined closely (\ref{fig:diff_date}), this difference corresponds to the modified date of the Historical Manuscript Record (2022-07-25) and the Novel Workflow Reexecution (2023-..).
While otherwise inconsequential, this difference provides a good litmus test for whether the article was indeed reexecuted or simply preserved, and should be expected throughout all comparisons.
Throughout other pages we see difference percentages which are broadly consistent across reexecutions, but vary from page to page over almost 2 degrees of magnitude.
Upon inspection, more variable but comparatively lower-percentage differences (pages 4 and 5, detail depicted in \cref{fig:diff_text}) are revealed as text differences, arising from the original article generating dynamic inline statistic summaries.
Higher-percentage differences (detail depicted in \cref{fig:diff_fig}) correspond to dynamically generated data figures, in which high variability of nondeterministic preprocessing results in changes of the majority of figure pixels.

%TODO chr discuss this more in discussions.
Notably, inspecting these differences reveals a strong coherence at the qualitative evaluation level in spite of high quantitative variability.
This coherence manifests in the statements from the original article remaining valid with regard to statistical summaries which emerge from  \textit{de novo} data processing (as seen in \ref{fig:diff_text}, \ref{fig:diff_fig}).
This is particularly true for p-values, the magnitude of which can vary substantially at the lower tail of the distribution without impacting qualitative statements, as long as magnitude notation is used.

%TODO chr discuss this more in discussions.
Further, we find that text differences are well localized, as a function of the original article implementing fixed decimal rounding for statistical outputs.
This, changes in the numerical value do not impact text length and do not generally propagate to subsequent lines, where they would be recorded as false positives.


\begin{figure}
	\centering
	\begin{subfigure}{0.99\textwidth}
		\centering
		\tcbox{
			\includegraphics[width=0.48\textwidth]{figs/diff_date.pdf}
			}
		\caption{
			The date change is correctly identified throughout the document, as seen in this example from page 1 of the article.
		}
		\label{fig:diff_date}
	\end{subfigure}
	\\
	\begin{subfigure}{0.99\textwidth}
		\centering
		\tcbox{
			\includegraphics[width=0.48\textwidth]{figs/diff_text.pdf}
			}
		\caption{
			Statistical summary values change, but maintain qualitative evaluation bracket with respect to e.g. p-value thresholds, as seen in this example from page 4 of the article.
		}
		\label{fig:diff_text}
	\end{subfigure}
	\\
	\vspace{1em}
	\begin{subfigure}{0.99\textwidth}
		\centering
		\tcbox{
			\includegraphics[width=0.8\textwidth]{figs/diff_fig.pdf}
			}
		\caption{
			In regression analysis, data points are highly variable, yet maintain a consistent slope and significance, as seen in this example from page 14 of the article.
		}
		\label{fig:diff_fig}
	\end{subfigure}
	\caption{
		\textbf{The article difference showcases expected quantitative and metadata variability, while maintaining overall validity of qualitative statements.}
		The figures are extracted from a full article \texttt{diff}, with hue-shifted highlighting (red for the Historical Manuscript Record, and blue for the Novel Workflow Reexecution).
	}
	\label{fig:diff}
\end{figure}


\subsection{Best Practice Guidelines}

As part of this work we have contributed substantial changes to the original OPFVTA repository, based on which we formulate a number of best practice guidelines, highly relevant in the production of reexecutable research outputs.

\subsubsection{Errors should be fatal more often than not.}
The high complexity of a full analysis workflow makes missing output data intractable, as there are many steps at which data may have been dropped.
Manually setting individual invocations propagate exit codes throughout the Make system is cumbersome, and thus an easy global invocation should be relied on so that errors become fatal and immediately visible.
This is bes accomplished by prepending all scripts for which this concern is relevant with a \texttt{set -eu} line.

\subsubsection{Hierarchical granularity greatly benefits efficiency.}
The high time cost of executing the full analysis workflow makes debugging errors very time-consuming.
Ideally it should not be necessary to re-execute the entire workflow once an error is potentially resolved.
For this it is beneficial to segment the workflow into as many hierarchical steps as feasible.
This is not always possible, and is particularly not feasible for higher-level statistical analysis, where hierarchical contingency can easily be lost.
However, particularly for such steps as preprocessing, and first-level general linear modelling, this is commonly feasible, and should be done.
An easy implementation of this is having the workflow coordination system check for the presence of each hierarchical result, and, if present, proceed to the next hierarchical step.

\subsubsection{Container image size should be kept small.}
Due to a lack of persistency, addressing issues in container image contents requires rebuilding, which can be a time-consuming process.
The smaller the container image, the easier it is.
In particular, when using containers, it is thus advisable to \textit{not} provide data via a package manager or via manual download inside the build script.
A suitable alternative is to assure provision of these resources outside of the container image, e.g. by bind-mounting Git (and DataLad) directories present on the host machine.

\subsubsection{Containers should fit the scope of the underlying workflow steps.}
In order to not artificially extend the workload of rebuilding a container image, it is further advisable to not create a bundled container image if separate containers can be used for separate hierarchical steps of the workflow.
Container image granularity is of course capped by article workflow granularity, but it is paramount to not compromise the former at the container level.
At a minimum, as seen in this study, the article reexecution container image should be distinct from container images required for producing a summary meta-article.

\subsubsection{Do not write debug-relevant data inside the container.}
Debug-relevant data, such as intermediary data processing steps or debugging logs should not be deleted by the workflow, and further, should be written to persistent storage.
When using containers, if this data is written to a hard-coded path, as they would be on a persistent operating system, it will disappear once the container is removed.
This data is vital for debugging, and thus should not be lost.
This can be avoided by making sure that the paths used for intermediary and debugging outputs are bind-mounted to real directories on the parent system, from which they can be freely inspected.

\subsubsection{Parameterize scratch directories.}
Complex workflows commonly generate large amounts of scratch data — intermediary data processing steps, with no other utility than being read by subsequent steps.
If these data are written to a hard-coded path, multiple executions will lead to race conditions, compromising one or multiple execution attempts.
This is avoided by parameterizing the path and/or setting a default value based on a unique string (e.g. generated from the timestamps).
When using containers, this should be done at the container initiation level, as the relevant path is the path on the parent system, and not the path inside the container.

\subsubsection{Dependency versions inside container environments should be frozen as soon as feasible.}
The need for image rebuilding also means that assuring functionality in view of frequent updates is a more difficult inside containers than on a persistent system.
This is compounded by the frequent and API-breaking update schedules of many scientific software packages.
While dependency version freezing is not without cost in terms of assuring continued real-life functionality for an article, it is paramount that this be done as soon as all required processing capabilities are provided.
How this is accomplished differs greatly based on the package manager used inside the container.
For the present example, using Gentoo's Portage package manager, versions can be frozen by checking out a specific commit of the dependency tree, in view of which the package manager will automatically resolve the same versions.

