\section{Discussion}

%  For the future efforts solutions such as https://github.com/ReproNim/reproseed/ could be used to either inform on the ways to seed specific applications or just to seed them via environment variables.

\subsection{Strengths of the original article as a reexecution target}
% this should be the shortest
The original paper made a significant effort to encapsulate all
components of the analysis as code, including the generation of images
and the rendering of the final pdf. The idea was that once properly installed, the
replication required little knowledge of the implementation details.
As with a data backup, which is not guaranteed to be good enough to recover
data until attempted, the reexecution of the original analysis was not guaranteed
until attempted.
This paper is a result of such reexecution attempt, and strives to present various
aspects, approaches, tips and tricks which could be useful for others who either are
planing to make their ongoing study reexecutable, or are attempting to reexecute
some prior study.

\subsection{Challenges}
Installation was challenging primarily because the process of installing
software on Gentoo is very slow. Building the container image took
about five hours, which lead to a slow development cycle where mistakes
were expensive.


%TODO avoiding duplication of paths
%TODO never hardcode abs paths (not that we did herE)
%TODO also avoid hard-coding relative paths which rely on specific execution directory
%TODOadd on set -eu -o pipefail

%TODO Latency for re-execution, checking intermediary steps

\subsection{Lessons Learned}
% mention decimal rounding for localized text diff-ing

\begin{itemize}
    \begin{itemize}
    \item
      Separate containers for major steps of data analysis, e.g., pre-processing and evaluation containers.
      In this study we had a single container for both steps and it added additional burden since to fix one of the stages we were affecting container for the both of them. 
    \item
      Standardize container ``interfaces'' to an existing standard like Boutiques or BIDS-App.
      BIDS-App interfaces also facilitate enabling ``per-participant'' processing, which then allows for mass-parallelization on HPC across subjects.
    \item
      The way opfvta is organized makes it challenging to modularize because it was designed for reproducibility and that was accomplished by abstracting the internal workings from a single top-level "black box" interface.
      \item What does a "chain" of BIDS apps look like?  Answer: mriqc, fmriprep, fitlins... The glue between -- data standards, but the software on how to invoke -- WiP, no unified way. WiP on formalizing BIDS-App interfaces more (https://bids.neuroimaging.io/bep027) which ATM assumes use of Boutique descriptors.
      \item Ideally, use images created by the projects with no modifications, i.e., for fmriprep use fmriprep container.
      \item Each container should have a well-defined "input" and "output" so it can be easily spotted which steps have failed.
  \item With singularity, automate the build from OCI push to datald repo, and then pull + datalad get from compute resource.
\end{itemize}

%TODO 
% Analogy with a "backup" -- there is no idea if a backup is any good until it is attempted to restore ffrom the backup. The same with studies claiming to be reproducible.


% TODO yoh : I do not understand this (chr) could you please expand this so I can write something more sensible about it?
%      \item Pay attention to user used for invocation of container
%
%        docker -- by default might be root, resultant files would be owned by root, not be able to move etc.
%
%        -e "UID=$(id -u)" -e "GID=$(id -g)"
%
%        and may be `-u` `-g` if used with ``docker''.
%    \end{itemize}

\subsection{Outlook}

- The linking of the data might make re-use/hacking of the article for variant purposes more feasible
- Automation of reference results
- Separation of components for re-use
