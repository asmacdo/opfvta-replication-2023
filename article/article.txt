UNDER REVIEW

Editorial

Appraising and Enhancing Reexecutability, Transparency,
and Portability of Published Neuroimaging Results

RESCIENCE X

Konrad Hinsen1,2, ID and Nicolas P. Rougier3,4,5, ID
1 Centre de Biophysique Moléculaire, CNRS UPR4301, Orléans, France – 2 Synchrotron SOLEIL, Division Expériences, Gif sur

Yvette, France – 3 INRIA Bordeaux Sud-Ouest, Bordeaux, France – 4 LaBRI, Université de Bordeaux, Institut Polytechnique de
Bordeaux, Centre National de la Recherche Scientifique, UMR 5800, Talence, France – 5 Institut des Maladies Neurodégénératives,
Université de Bordeaux, Centre National de la Recherche Scientifique, UMR 5293, Bordeaux, France

Edited by
(Editor)
Reviewed by
(Reviewer 1)
(Reviewer 2)
Received
—
Published
—
DOI
—

caption subcaption

1 Abstract
The value of experimental research articles is inextricably contingent on data analysis
results, which substantiate their natural language claims. Such processes are highly and
increasingly complex, and the instructions required to generate them are a cornerstone
element of scientific work. However, their intricacy and high reliance on extraneous
tools makes these analysis processes potentially fragile. Thus it is of crucial importance
for full article generation instructions to be not only recorded and accessible, but also
formatted in such a way as to support robust reexecution. In this article we examine a
neuroimaging study which already publishes full article reexecution instructions, and
detail the most prominent difficulties, arising chiefly from API stability of dependency
libraries. Further, we propose an emerging reference reexecution standard which lever‐
ages explicit dependency management as well as container technologies, in order to
improve portability, provenance tracking, and ease of reexecution. Lastly, we ascer‐
tain the reproduction accuracy within the new environment in light of common non‐
deterministic steps in data processing, and discuss how to reduce the most widespread
instances of non‐deterministic behaviour.

2 Background
2.1 Reexecutable Research
While the reproducibility of research findings (i.e. independently verifying a published
result or phenomenon) has received considerable attentionTODO , reexecutability has re‐
mained largely unexplored as a discrete phenomenon. While the scope of reexecution is
narrower, it constitutes a more well‐defined and therefore tractable issue in improving
the quality and sustainability of research. On one hand reexecution is a prerequisite for
the reproduction of any research which prominently features computational analysis —
which encompasses a growing segment of modern experimental research. On the other
hand reexecution constitutes a capability in and of itself, with ample utility in education,
Copyright © 2023 K. Hinsen and N.P. Rougier, released under a Creative Commons Attribution 4.0 International license.
Correspondence should be addressed to Nicolas P. Rougier (Nicolas.Rougier@inria.fr)
The authors have declared that no competing interests exists.
Code is available at https://github.com/rescience-c/template.

ReScience C 4.1 – Hinsen and Rougier 2023

1

Appraising and Enhancing Reexecutability, Transparency, and Portability of Published Neuroimaging Results

UNDER REVIEW

training, rapid‐feedback development, and resource reuse for novel research purposes
(colloquially, “hacking”) — which may accrue even in the absence of reproducibility of
accurate reproducibility of results.
Free and Open Source Softwarefoss has permeated the world of research to a significant
extent, and it is presently not uncommon for researchers to freely and or openly pub‐
lish part of the analysis instructions used in generating published resultsTODO . How‐
ever, such instructions are commonly disconnected from the research output document,
which is manually constructed from static inputs. Consequently, data analysis outputs
are not generated in their respective contexts, and therefore disconnected from the pos‐
itive claims which they support. This precludes automatic reexecution of the full re‐
search output, and limits their potential for re‐use.
In order to optimally leverage extant efforts pertaining to full article reexecution and in
order to test reexecutability in the face of high task complexity, we have selected a novel
neuroimaging study, identified as OPFVTA based on author naming conventionsopfvta .
The 2022 article is accompanied by a programmatic workflow via which it can be fully
regenerated, based solely on raw data, data analysis instructions, and natural‐language
commentary — and which is initiated via a simple executable script in the ubiquitous
GNU Bashbash command language. The reexecution process relies on an emerging in‐
frastructure standard, RepSePrepsep , which is used by additional other articles, thus pro‐
viding a larger scope for conclusion drawn and standards formulated as part of this
study.

2.2 Data Analysis
One of the hallmarks of scientific data analysis is its intricacy — resulting from the mul‐
tifaceted confounds which need to be accounted for, as well as from the breadth of
questions which extant tools need to be adapted in order to address. Data analysis, can
be subdivided into data preprocessing and data evaluation. The former consists of data
cleaning, reformatting, standardization, and sundry processes required for data to be
suitable for evaluation. Data evaluation consists of various types of modelling, usually
applied in sequence at various hierarchical steps.
In the general case of stimulus‐evoked neuroimaging analysis, as seen in the OPFVTA
article, data evaluation is commonly subdivided into “level one” (i.e. within‐subject)
analysis, and “level two” (i.e. across‐subject) analysis, with the results of the latter be‐
ing further reusable for higher‐level analysesFriston1995 . In effect, these modelling steps
usually represent iterative applications of General Linear Modelling (GLM), at increas‐
ingly higher orders of abstraction.
Computationally, the various steps of a data analysis pipeline are sharply distinguished
by their time cost. By far the most expensive element in the aforementioned reference
pipeline is a substage of data preprocessing known as registration. This commonly re‐
lies on iterative gradient descent and can additionally require high‐density sampling de‐
pending on the feature density of the data. The second most costly step is the first‐level
GLM, the cost of which is mostly due to the high number of voxels modelled individually
for each subject.
The impact of these time costs on reexecution is that rapid‐feedback development and
debugging can be compromised if the reexecution is monolithic. While ascertaining the
effect of changes in the registration instructions on the final result unavoidably neces‐
sitate the reexecution of the entire pipeline, editing natural‐language commentary in
the article text, or adapting figure styles, should not. To this end the reference article of
this study employs a hierarchical Bash‐script structure, with data preprocessing and all
data evaluation steps which operate in voxel space being handled by a sub‐script, and
top‐level (i.e. inline) statistics, figure, and TeX‐based article generation in a separate

ReScience C 4.1 – Hinsen and Rougier 2023

2

Appraising and Enhancing Reexecutability, Transparency, and Portability of Published Neuroimaging Results

UNDER REVIEW

sub‐script. The nomenclature to distinguish these two phases is “high‐iteration” and
“low‐iteration”repsep .
Analysis dependency tracking, which is to say monitoring whether files required for
the next hierarchical step have changed — and thus whether that step needs to be re‐
executed — is handled for high‐iteration analysis script via the RepSeP infrastructure,
but not for the low‐iteration script.

2.3 Software Dependency Management
Beyond the hierarchically evolving data dependencies, which can be considered inter‐
nal to the workflow, any data analysis workflow has additional dependencies in the form
of software. This refers to the computational tools called by the workflow — and, given
the diversity of research applications, may encompass numerous and complex pieces
of software. Complexity in this sense also refers to the fact that individual software de‐
pendencies commonly come with their own software dependencies, which may in turn
have further dependencies, and so on. This is known as a dependency graph, which is
commonly handled by a package manager.
The OPFVTA article in its original form relies on Portageportage , a package manager char‐
acterized by providing integration across programming languages, source‐based pack‐
age installation, and wide‐ranging support for neuroscience softwareng . As such, the
dependencies of the workflow are summarized in a standardized format, which is called
an Ebuild. This format is analogous to the format used to specify dependencies at all
further hierarchical levels in the dependency tree. This affords a homogeneous envi‐
ronment for dependency resolution, as specified by the Package Manager Standardpms .
Additionally, the reference article contextualizes its raw data origin point as a depen‐
dency, providing provenance tracking in the same fashion as for software.
While the top‐level Ebuild (i.e. the software dependency requirements of the workflow)
is included in the article repository and distributed alongside it, the Ebuilds tracking
dependencies further down the tree are all distributed via separate repositories. These
repositories are version controlled, meaning that their state at any time point is docu‐
mented, and they can thus be restored to represent the environment as it would have
been generated at any point in the past.

2.4 Containers
Operating system virtualization is a process whereby an operating system can be in‐
stalled inside another operating system, without being subject to the environment con‐
straints of its parent, and without potentially polluting the parent environment. Given
the complexity of scientific computing environments, such virtualization is attractive
on multi‐user systems, on systems with lacking package management capabilities, or
in instances where the tasks to be executed are fragile and may require bespoke con‐
straints.
One of the prominent instantiations of virtualization are containers, a technology which
focuses on portability of operating system images (i.e. containers) across parent oper‐
ating systems featuring the correct container environment. Their relevance to open
science consists in providing end‐users with an accessible environment, which can be
ascertained to provide the requirements of a certain top‐level workflow, and which does
not interfere with their parent environment.
While the reference OPFVTA article does not leverage this technology, containers can
improve its portability, as well as provide a snapshot of its functioning at a certain point
in time — mitigating process fragility over evolving software dependencies.

ReScience C 4.1 – Hinsen and Rougier 2023

3

Appraising and Enhancing Reexecutability, Transparency, and Portability of Published Neuroimaging Results

UNDER REVIEW

Pixels Differ [%]

10 1

10 2

10 3

10 4
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21

Page

Figure 1. Page‐wise visual differences between the Historical Manuscript Record and the Novel
Workflow Reexecution help identify overall reproduction fidelity, and identify pages with note‐
worthy differences. Depicted are rasterized document differences, weighted 1 for changes in any
pixel color channel, and rounded to four decimal points. The scale is logarithmic, and the hue
color map is linear.

3 Results
We compare the difference between the Historical Manuscript Record — a product of
the original executable article generation — and the Novel Workflow Reexecution, and
find strong overall coherence.

3.1 Repository Structure
In order to improve the reexecution reliability of the OPVFTA article we have constructed
a parent repository encompassing the original article (including updates resulting as
part of this study), the raw data it operates on, as well as container image and container
execution instructions. This layout type is known as YODA (a recursive acronym for
“YODAs Organigram on Data Analysis”) and aims to facilitate reproducible research and
good provenance tracking practices.
Notably, this repository structure diverges from the original reference article in directly
linking the data at the repository level, as opposed to relying on its installation via the
package manager. Within the context of container usage, this affords the advantage
of keeping the data packages separate and not adding their disk space requirements to
those of the container image.
In this novel repository structure, external components of the article are managed as Git
submodules, with data sumbodules being handled by git‐annex, a versioning technology
suitable for binary files, and made accessible via datalad.

ReScience C 4.1 – Hinsen and Rougier 2023

4

Appraising and Enhancing Reexecutability, Transparency, and Portability of Published Neuroimaging Results

UNDER REVIEW

[b]0.48
Figure 2. Caption

[b]0.48
Figure 3. Caption

opfvta-reexecution/
Makefile
code/

inputs/

paper/

outputs/

produce-analysis.sh
images/

opfvta/

Containerfile

...

opfvta_bidsdata/
...

mouse-brain-templates/
...

generated/
TODO2

source/
...

Makefile

TODO1

Containerflie.latex

Figure 4. This is a caption

ReScience C 4.1 – Hinsen and Rougier 2023

5

Appraising and Enhancing Reexecutability, Transparency, and Portability of Published Neuroimaging Results

UNDER REVIEW

4 Methods
yoh: this could be the section to mention approaches tried but which were not taken to
lead to what is presented in the results.
that is where to mention/refer to

repronim 5 steps https://www.repronim.org/5steps.html and https://www.sciencedirect.com/science/article/

4.1 Data Acquisition
No new data was recorded, we have reused the data collected for [the original paper][horea‐
paper].
TODO(Brief summary of data collection methods in original paper) yoh: I would not
bother – just refer to original paper
TODO(How the data was stored and how we got it) yoh: exactly – let’s describe how we
acquired” data from original resources: tarballs etc, placed into datalad datasets. refer
where possible to the handbook.

4.2 Computing Environments
4.3 YODA
yoh: to bind it all up

4.4 Provenance
datalad run/containers‐run

4.5 Paper figure reproducibility aspects
pointers to the Horea’s setups etc. How used here... containers for the paper etc, github
etc

5 Discussion
5.1 Strengths of the original article as a reexecution target
The original paper made a significant effort to encapsulate all components of the analy‐
sis as code, including the generation of images and the rendering of the final pdf. Once
properly installed, the replication required little knowledge of the implementation de‐
tails.

5.2 Challenges
Installation was challenging primarily because the process of installing software on Gen‐
too is very slow. Building the container image took about five hours, which lead to a slow
development cycle where mistakes were expensive.

ReScience C 4.1 – Hinsen and Rougier 2023

6

Appraising and Enhancing Reexecutability, Transparency, and Portability of Published Neuroimaging Results

UNDER REVIEW

5.3 Outlook
‐ The linking of the data might make re‐use/hacking of the article for variant purposes
more feasible ‐ Automation of reference results ‐ Separation of components for re‐use
ReScience C & ReScience X — The biggest and most visible change we would like to pro‐
pose is to change the name of the journal “ReScience” in favor of “ReScience C” where
the C stands for (c)omputational. This change would be necessary to have consistent
naming with the upcoming creation of the “ReScience X” journal that will be dedicated
to e(x)perimental replications and co‐directed by E.Roesch (University of Reading) and
N.Rougier (University of Bordeaux). The name “ReScience” would then be used for the
name of a non‐profit organization (that is yet to be created) for the two journals as well
as future journals (such as the utopian CoScienceRougier:2017 or a future and tentative “Re‐
Science T” for theoretical science).
A new submission process — The current submission process requires authors to fork, clone
and branch the submission repository in order to write their article and to place code
and data at the relevant places in the forked repository. Once done, authors have to
push their changes and to make a pull request that is considered as a submission. This
process is cumbersome for authors and has induced many troubles for editors as well
once the article is accepted and ready to be published, mostly because of the complexity
of the editing procedure. In order to make life easier for everyone, we greatly simplified
the submission process for ReScience C and X. Authors are now responsible for getting a
DOI for their code & data and only have to submit a PDF and a metadata file in a GitHub
issue. We also provide Python programs that largely automate the subsequent editing
process. We will still archive the submission on Zenodo but this archive will be made
for the final PDF only. However, both the PDF and the Zenodo entry will contain all
associated DOIs (data and code).
A simplified publishing process — In ReScience, we have have been using a combination
of markdown and pandoc for producing both the draft and the final version of all the
published articles. This had worked reasonably well until it started to cause all kind of
problems for both authors and editors, especially with the reference and citation plug‐
ins. Consequently, articles will be now submitted directly in PDF with accompanying
metadata in a separate file using the YAML format (they were previously embedded in
the markdown file). Once an article has been accepted, authors will be responsible
for updating the metadata and for rebuilding the PDF if necessary. We could also con‐
sider using the Whedon API that helps with automating most of the editorial tasks for
JOSS and JOSE. This will most probably require some tweaking because our publishing
pipeline is a bit different.
A new design — The combination of markdown and pandoc has also severely limited the
layout and style possibilities for the article template and since we are switching to LATEX,
this is the opportunity to propose a new design based on a more elegant style, using
a new font stackSourceSerifPro:2014, Roboto:2011, SourceCodePro:2012 (you are currently reading it).
The goal is to have a subtle but strong identity with enhanced readability. Considering
that articles will be mostly read on screen (as opposed to printed), we can benefit from
a more ethereal style. Once this design will have stabilized, an overleaf template will be
made available for those without a TEX installation. If a TEX expert is ready to help review
the template (and possibly rewrite it as a class), their help would be much welcome and
appreciated. The same holds for LibreOffice, Word or Pages, any template is welcome,
just contact us beforehand such that we can coordinate efforts.

ReScience C 4.1 – Hinsen and Rougier 2023

7

Appraising and Enhancing Reexecutability, Transparency, and Portability of Published Neuroimaging Results

UNDER REVIEW

Editorials, letters and special issues — ReScience C remains dedicated to the publication of
computational replications but we (i.e., the editorial team) would like to have the oppor‐
tunity to publish editorials when deemed necessary and to give anyone the opportunity
to write letters to the community on a specific topic related to reproducibility. Both edito‐
rials and letters are expected to be 1 or 2 pages long (but no hard limit will be enforced),
will be (quickly) peer reviewed, and will be assigned a DOI. Furthermore, with the ad‐
vent of reproducibility hackatons worldwide, we will host special issues with guest editors
(such as, for example, the organizers of a hackaton) in order to publish the results and
to enhance their discoverability. Each entry will have to go through the regular open
peer‐reviewed pipeline.
We hope that most readers will agree on the proposed changes such that we can commit
to them in the next few weeks. The review for this editorial is open (as usual) and any‐
one can comment on and/or oppose any of the proposed changes. New ideas are also
welcome.

ReScience C 4.1 – Hinsen and Rougier 2023

8

